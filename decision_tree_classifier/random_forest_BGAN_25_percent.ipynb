{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2mw1lAayojx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing \n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "##############################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import random\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles, make_moons \n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    " \n",
    " \n",
    "import torch.nn.functional as Fnc\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from IPython.core.debugger import set_trace\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "###############################################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as Func\n",
    "import sys\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BWanctKlyoj0"
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12872,
     "status": "ok",
     "timestamp": 1575248855275,
     "user": {
      "displayName": "Nur Imtiazul Haque",
      "photoUrl": "",
      "userId": "15560043854638298091"
     },
     "user_tz": 300
    },
    "id": "kDVtb4eNXUVM",
    "outputId": "51651834-0ce6-43cf-fb5c-aa7f8d580b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  0\n",
      "(413, 21)\n",
      "(138, 21)\n",
      "Label:  1\n",
      "(6, 21)\n",
      "(2, 21)\n",
      "Label:  2\n",
      "(6, 21)\n",
      "(2, 21)\n",
      "Label:  3\n",
      "(10, 21)\n",
      "(4, 21)\n",
      "Label:  4\n",
      "(2, 21)\n",
      "(1, 21)\n",
      "Label:  5\n",
      "(234, 21)\n",
      "(78, 21)\n",
      "Label:  6\n",
      "(4, 21)\n",
      "(2, 21)\n",
      "Label:  7\n",
      "(2, 21)\n",
      "(1, 21)\n",
      "Label:  8\n",
      "(5, 21)\n",
      "(2, 21)\n",
      "Label:  9\n",
      "(20100, 21)\n",
      "(6701, 21)\n",
      "Label:  10\n",
      "(43, 21)\n",
      "(15, 21)\n",
      "Label:  11\n",
      "(18240, 21)\n",
      "(6080, 21)\n",
      "Label:  12\n",
      "(2, 21)\n",
      "(1, 21)\n",
      "Label:  13\n",
      "(3, 21)\n",
      "(1, 21)\n",
      "Label:  14\n",
      "(49, 21)\n",
      "(17, 21)\n",
      "Label:  15\n",
      "(195, 21)\n",
      "(65, 21)\n",
      "Label:  16\n",
      "(2, 21)\n",
      "(1, 21)\n",
      "Label:  17\n",
      "(298, 21)\n",
      "(100, 21)\n",
      "Label:  18\n",
      "(52648, 21)\n",
      "(17550, 21)\n",
      "Label:  19\n",
      "(1, 21)\n",
      "(1, 21)\n",
      "Label:  20\n",
      "(183, 21)\n",
      "(62, 21)\n",
      "Label:  21\n",
      "(191, 21)\n",
      "(64, 21)\n",
      "Label:  22\n",
      "(3, 21)\n",
      "(2, 21)\n",
      "n_sample: 20100 max_sample: 52648 need_to_create: 0\n",
      "n_sample: 18240 max_sample: 52648 need_to_create: 0\n",
      "n_sample: 413 max_sample: 52648 need_to_create: 87\n",
      "n_sample: 298 max_sample: 52648 need_to_create: 202\n",
      "n_sample: 234 max_sample: 52648 need_to_create: 266\n",
      "n_sample: 195 max_sample: 52648 need_to_create: 305\n",
      "n_sample: 191 max_sample: 52648 need_to_create: 309\n",
      "n_sample: 183 max_sample: 52648 need_to_create: 317\n",
      "n_sample: 49 max_sample: 52648 need_to_create: 451\n",
      "n_sample: 43 max_sample: 52648 need_to_create: 457\n",
      "n_sample: 10 max_sample: 52648 need_to_create: 490\n",
      "n_sample: 6 max_sample: 52648 need_to_create: 494\n",
      "n_sample: 6 max_sample: 52648 need_to_create: 494\n",
      "n_sample: 5 max_sample: 52648 need_to_create: 495\n",
      "n_sample: 4 max_sample: 52648 need_to_create: 496\n",
      "n_sample: 3 max_sample: 52648 need_to_create: 497\n",
      "n_sample: 3 max_sample: 52648 need_to_create: 497\n",
      "n_sample: 2 max_sample: 52648 need_to_create: 498\n",
      "n_sample: 2 max_sample: 52648 need_to_create: 498\n",
      "n_sample: 2 max_sample: 52648 need_to_create: 498\n",
      "n_sample: 2 max_sample: 52648 need_to_create: 498\n",
      "n_sample: 1 max_sample: 52648 need_to_create: 499\n"
     ]
    }
   ],
   "source": [
    "############################   DATA SET LOAD  #########################\n",
    "\n",
    "def sortingFunction(data):\n",
    "    return data.shape[0]\n",
    "\n",
    "#### label coding for nominal values\n",
    "def label_coding(label):\n",
    "    dataset[label]= label_encoder.fit_transform(dataset[label]) \n",
    "    dataset[label].unique()\n",
    "    \n",
    "### \n",
    "def crop_dataset(len_dataset):\n",
    "    for label in range(len_dataset):\n",
    "        temp_dataframe=dataset[dataset['label']==label]\n",
    "        \n",
    "        try:\n",
    "            if temp_dataframe.shape[0]>8:\n",
    "                _ ,temp_dataframe = train_test_split(temp_dataframe,test_size =0.25)\n",
    "            temp_train ,temp_test = train_test_split(temp_dataframe,test_size=0.25)\n",
    "            print(\"Label: \",str(label))\n",
    "            print(temp_train.shape)\n",
    "            print(temp_test.shape)\n",
    "                \n",
    "        except:\n",
    "            print(\"Error for \"+str(label))\n",
    "        list_train.append(temp_train)\n",
    "        list_test.append(temp_test)\n",
    "        \n",
    "def new_sample_generation(x,y,z):\n",
    "    need=500-x if x<=500 else 0\n",
    "    print(\"n_sample: \"+str(x)+\" max_sample: \"+str(y)+\" need_to_create: \"+str(need))\n",
    "    \n",
    "### importing dataset\n",
    "dataset = pd.read_csv('kddcup99_csv.csv')\n",
    "\n",
    "### label encoding\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "label_coding('protocol_type')\n",
    "label_coding('service')\n",
    "label_coding('flag')\n",
    "label_coding('label')\n",
    "\n",
    "### extracting features\n",
    "X=dataset.iloc[:,:-1]\n",
    "X=X.values\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "### dimention reduction\n",
    "\n",
    "################################   PCA #####################################################\n",
    "\n",
    "number_of_components=20\n",
    "pca = PCA(n_components=number_of_components)\n",
    "columns_array=[]\n",
    "for i in range (number_of_components):\n",
    "    columns_array.append(\"principal_Component\"+str(i+1))\n",
    "    \n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "              , columns = columns_array)\n",
    "\n",
    "finalDf = pd.concat([principalDf, dataset[['label']]], axis = 1)\n",
    "dataset=finalDf\n",
    "\n",
    "\n",
    "\n",
    "#############################  CROP DATA SET up to 15 Labels  ###########################\n",
    "\n",
    "len_dataset= len(dataset.label.unique())\n",
    "list_train,list_test=[],[]\n",
    "    \n",
    "crop_dataset(len_dataset)\n",
    "\n",
    "list_train.sort(key=sortingFunction,reverse=True)\n",
    "list_test.sort(key=sortingFunction,reverse=True)\n",
    "\n",
    "train_dataframe=list_train[0]\n",
    "test_dataframe=list_test[0]\n",
    "\n",
    "# to take top 15 labels\n",
    "labels_to_consider = 23\n",
    "max_samples = list_train[0].shape[0]\n",
    "\n",
    "for i in range(1,labels_to_consider):\n",
    "    new_sample_generation(len(list_train[i]),max_samples,int((max_samples-len(list_train[i]))*.5))\n",
    "    train_dataframe=pd.concat([train_dataframe,list_train[i]])\n",
    "    test_dataframe=pd.concat([test_dataframe,list_test[i]])\n",
    "\n",
    "partial_dataframe=pd.concat([train_dataframe,test_dataframe])\n",
    "\n",
    "#print(len(test_dataframe.label.unique()))\n",
    "\n",
    "####################################  Generating Numpy Array X,y ###################\n",
    "\n",
    "x_train=np.array(train_dataframe.iloc[:,:-1])\n",
    "x_test=np.array(test_dataframe.iloc[:,:-1])\n",
    "y_train=np.array(train_dataframe.iloc[:,-1])\n",
    "y_test=np.array(test_dataframe.iloc[:,-1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12867,
     "status": "ok",
     "timestamp": 1575248855276,
     "user": {
      "displayName": "Nur Imtiazul Haque",
      "photoUrl": "",
      "userId": "15560043854638298091"
     },
     "user_tz": 300
    },
    "id": "29QwYqs-yoj4",
    "outputId": "dae88565-c442-4e81-ebc6-646dfe15ad39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12860,
     "status": "ok",
     "timestamp": 1575248855276,
     "user": {
      "displayName": "Nur Imtiazul Haque",
      "photoUrl": "",
      "userId": "15560043854638298091"
     },
     "user_tz": 300
    },
    "id": "VEaEgszKyoj6",
    "outputId": "fcb42386-bb4c-4639-dcd0-ef47b45273d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bdgpb7HSXUVY"
   },
   "outputs": [],
   "source": [
    "# ######################  IDS  ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9988345742958886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nur Imtiazul Haque\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Socre  0.7245838035038268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  136,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     2,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     4,     0,     0,     0,     0,     0,\n",
       "            0,     0,     1,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,    72,     0,     0,     0,\n",
       "            0,     0,     2,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     2,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     1,     0,     0,     0,     0,\n",
       "         6699,     0,     1,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     1,     0,     0,     0,\n",
       "            0,    14,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    2,     0,     2,     0,     0,     5,     0,     1,     2,\n",
       "            2,     1,  6074,     0,     0,     0,     1,     1,     5,\n",
       "            0,     1,     0,     4,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     1,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     1,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,    17,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,    63,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     1,     0,    95,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "        17550,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,    62,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     2,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,    60,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     2]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model using Decision tree classifier\n",
    "classifier =  RandomForestClassifier(n_estimators=100, max_depth=20, random_state=0)\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "# metrics\n",
    "prediction_actual=classifier.predict(x_test)\n",
    "actual_accuracy=accuracy_score(prediction_actual,y_test)\n",
    "print(\"Accuracy \",actual_accuracy)\n",
    "print(\"F1 Socre \", f1_score(prediction_actual,y_test, average='macro'))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(prediction_actual,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 854168,
     "status": "ok",
     "timestamp": 1575249696630,
     "user": {
      "displayName": "Nur Imtiazul Haque",
      "photoUrl": "",
      "userId": "15560043854638298091"
     },
     "user_tz": 300
    },
    "id": "wGr9EZ0PXUVj",
    "outputId": "4479b742-5435-4fe6-83a5-15aac65dfa34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nur Imtiazul Haque\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       138\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.80      1.00      0.89         4\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.97      0.92      0.95        78\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       1.00      1.00      1.00      6701\n",
      "          10       0.93      0.93      0.93        15\n",
      "          11       1.00      1.00      1.00      6080\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00        17\n",
      "          15       1.00      0.97      0.98        65\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.99      0.95      0.97       100\n",
      "          18       1.00      1.00      1.00     17550\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       1.00      1.00      1.00        62\n",
      "          21       0.97      0.94      0.95        64\n",
      "          22       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00     30890\n",
      "   macro avg       0.72      0.73      0.72     30890\n",
      "weighted avg       1.00      1.00      1.00     30890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################  EVALUATING PERFORMANCE of IDS ########################\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,prediction_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nur Imtiazul Haque\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       537\n",
      "           1       0.60      0.50      0.55         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.94      0.94      0.94        17\n",
      "           4       1.00      0.33      0.50         3\n",
      "           5       0.97      0.98      0.98       315\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      0.25      0.40         4\n",
      "           9       1.00      1.00      1.00     26865\n",
      "          10       0.98      0.85      0.91        53\n",
      "          11       1.00      1.00      1.00     24392\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      0.99      0.99        72\n",
      "          15       0.99      0.99      0.99       275\n",
      "          16       0.67      0.40      0.50         5\n",
      "          17       0.99      0.95      0.97       393\n",
      "          18       1.00      1.00      1.00     70070\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       1.00      1.00      1.00       253\n",
      "          21       0.99      0.92      0.95       234\n",
      "          22       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           1.00    123505\n",
      "   macro avg       0.86      0.75      0.78    123505\n",
      "weighted avg       1.00      1.00      1.00    123505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################Ultimate Performance#########################\n",
    "\n",
    "dataset=finalDf\n",
    "X=dataset.iloc[:,:-1]\n",
    "y=dataset.iloc[:,-1]\n",
    "\n",
    "# train model using Decision tree classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = .25, random_state = 0)\n",
    "\n",
    "# metrics\n",
    "prediction_actual=classifier.predict(x_test)\n",
    "actual_accuracy=accuracy_score(prediction_actual,y_test)\n",
    "print(classification_report(y_test, prediction_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8s5K4MyyokH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98139, 20) (30890, 20) (98139, 1) (30890, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"x_train.csv\").values\n",
    "x_test = pd.read_csv(\"x_test.csv\").values\n",
    "y_train=pd.read_csv(\"y_train.csv\").values\n",
    "y_test=pd.read_csv(\"y_test.csv\").values\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nur Imtiazul Haque\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Nur Imtiazul Haque\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       138\n",
      "         1.0       1.00      0.50      0.67         2\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       1.00      1.00      1.00         4\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "         5.0       0.96      0.97      0.97        78\n",
      "         6.0       1.00      1.00      1.00         2\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         8.0       0.50      0.50      0.50         2\n",
      "         9.0       1.00      1.00      1.00      6701\n",
      "        10.0       0.93      0.93      0.93        15\n",
      "        11.0       1.00      1.00      1.00      6080\n",
      "        12.0       1.00      1.00      1.00         1\n",
      "        13.0       1.00      1.00      1.00         1\n",
      "        14.0       1.00      1.00      1.00        17\n",
      "        15.0       0.98      0.97      0.98        65\n",
      "        16.0       0.00      0.00      0.00         1\n",
      "        17.0       1.00      0.96      0.98       100\n",
      "        18.0       1.00      1.00      1.00     17550\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        20.0       1.00      1.00      1.00        62\n",
      "        21.0       1.00      0.83      0.91        64\n",
      "        22.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           1.00     30890\n",
      "   macro avg       0.76      0.70      0.72     30890\n",
      "weighted avg       1.00      1.00      1.00     30890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train model using Decision tree classifier\n",
    "classifier =  RandomForestClassifier(n_estimators=100, max_depth=20, random_state=0)\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "# metrics\n",
    "prediction_actual=classifier.predict(x_test)\n",
    "actual_accuracy=accuracy_score(prediction_actual,y_test)\n",
    "print(classification_report(y_test, prediction_actual))\n",
    "#print(\"Accuracy \",actual_accuracy)\n",
    "#print(\"F1 Socre \", f1_score(prediction_actual,y_test, average='macro'))\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#confusion_matrix(prediction_actual,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nur Imtiazul Haque\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       537\n",
      "           1       0.67      0.33      0.44         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       1.00      0.94      0.97        17\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.98      0.98      0.98       315\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      0.25      0.40         4\n",
      "           9       1.00      1.00      1.00     26865\n",
      "          10       0.98      0.85      0.91        53\n",
      "          11       1.00      1.00      1.00     24392\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       0.97      1.00      0.99        72\n",
      "          15       0.98      0.99      0.98       275\n",
      "          16       1.00      0.20      0.33         5\n",
      "          17       1.00      0.95      0.97       393\n",
      "          18       1.00      1.00      1.00     70070\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       1.00      0.99      1.00       253\n",
      "          21       0.99      0.89      0.93       234\n",
      "          22       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           1.00    123505\n",
      "   macro avg       0.88      0.77      0.80    123505\n",
      "weighted avg       1.00      1.00      1.00    123505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################Ultimate Performance#########################\n",
    "\n",
    "dataset=finalDf\n",
    "X=dataset.iloc[:,:-1]\n",
    "y=dataset.iloc[:,-1]\n",
    "\n",
    "# train model using Decision tree classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = .25, random_state = 0)\n",
    "\n",
    "# metrics\n",
    "prediction_actual=classifier.predict(x_test)\n",
    "actual_accuracy=accuracy_score(prediction_actual,y_test)\n",
    "print(classification_report(y_test, prediction_actual))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BGAN_25_Percent.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
